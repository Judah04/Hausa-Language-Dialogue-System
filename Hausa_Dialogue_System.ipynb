{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a676ff5-3d05-48e2-be6f-2428ce24934c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "import numpy as np\n",
    "import torch\n",
    "import soundfile as sf\n",
    "from transformers import pipeline, SpeechT5Processor, SpeechT5ForTextToSpeech, SpeechT5HifiGan\n",
    "from huggingface_hub import hf_hub_download\n",
    "\n",
    "theme = gr.themes.Base(\n",
    "    primary_hue=\"orange\",\n",
    "    secondary_hue=\"orange\",\n",
    ").set(\n",
    "    button_secondary_background_fill='*primary_500',\n",
    "    button_secondary_background_fill_dark='*secondary_600'\n",
    ")\n",
    "\n",
    "# Load ASR and Text Generation Pipelines\n",
    "speech_recognition = pipeline(\"automatic-speech-recognition\", model=r\"C:\\Users\\user\\Documents\\project\\101stt\")\n",
    "chatbot = pipeline(\"text-generation\", model=r\"C:\\Users\\user\\Documents\\project\\10bot\")\n",
    "\n",
    "# Function to handle audio transcription\n",
    "def transcribe_audio(audio):\n",
    "    # Extract sampling rate and audio data\n",
    "    sr, y = audio\n",
    "    y = y.astype(np.float32)\n",
    "    y /= np.max(np.abs(y))  # Normalize audio signal\n",
    "    return speech_recognition({\"sampling_rate\": sr, \"raw\": y})[\"text\"]\n",
    "\n",
    "\n",
    "# Function to generate chatbot response\n",
    "def generate_response(message, history):\n",
    "    return \"\", history  + [[message, None]]# Returning empty input box and updated history\n",
    "\n",
    "def bot(history):\n",
    "    user_message = history[-1][0]\n",
    "    new_user_input_ids = tokenizer.encode(\n",
    "        user_message + tokenizer.eos_token, return_tensors=\"pt\"\n",
    "    )\n",
    "\n",
    "    # append the new user input tokens to the chat history\n",
    "    bot_input_ids = torch.cat([torch.LongTensor([]), new_user_input_ids], dim=-1)\n",
    "\n",
    "    # generate a response\n",
    "    response = model.generate(\n",
    "        bot_input_ids, max_length=1000, pad_token_id=tokenizer.eos_token_id\n",
    "    ).tolist()\n",
    "\n",
    "    # convert the tokens to text, and then split the responses into lines\n",
    "    response = tokenizer.decode(response[0]).split(\"<|endoftext|>\")\n",
    "    response = [\n",
    "        (response[i], response[i + 1]) for i in range(0, len(response) - 1, 2)\n",
    "    ]  # convert to tuples of list\n",
    "    history[-1] = response[0]\n",
    "    return history\n",
    "\n",
    "\n",
    "# Text-to-Speech (TTS)\n",
    "def load_speaker_embedding(filepath: str) -> torch.Tensor:\n",
    "    embedding_npy = np.load(filepath)\n",
    "    return torch.tensor(embedding_npy).unsqueeze(0)\n",
    "\n",
    "def synthesize_speech(text: str, embedding_file_path: str):\n",
    "    # Load processor, model, and vocoder\n",
    "    processor = SpeechT5Processor.from_pretrained(r\"C:\\Users\\user\\Documents\\project\\t5tts\")\n",
    "    model = SpeechT5ForTextToSpeech.from_pretrained(r\"C:\\Users\\user\\Documents\\project\\t5tts\")\n",
    "    vocoder = SpeechT5HifiGan.from_pretrained(r\"C:\\Users\\user\\Documents\\project\\t5tts\\hifigan\")\n",
    "\n",
    "    # Prepare inputs and load speaker embedding\n",
    "    inputs = processor(text=text, return_tensors=\"pt\")\n",
    "    speaker_embedding = load_speaker_embedding(r\"C:\\Users\\user\\Documents\\project\\t5tts\\speaker_em.npy\")\n",
    "\n",
    "    # Generate speech\n",
    "    with torch.no_grad():\n",
    "        speech = model.generate_speech(inputs[\"input_ids\"], speaker_embedding, vocoder=vocoder)\n",
    "\n",
    "    # Save generated audio to .wav file and return path\n",
    "    output_file = \"tts_example.wav\"\n",
    "    sf.write(output_file, speech.numpy(), samplerate=16000)\n",
    "    return output_file\n",
    "\n",
    "\n",
    "\n",
    "# Gradio Interface\n",
    "with gr.Blocks(theme=theme) as demo:\n",
    "    gr.Markdown(\"# Hausa Chatbot tare da Gane Magana da TTS\")\n",
    "\n",
    "    # Define chatbot with message history\n",
    "    # chatbot = gr.Chatbot(type = \"messages\")\n",
    "    chatbot = gr.Chatbot()\n",
    "\n",
    "    # Audio input, transcription, and text-to-speech components\n",
    "    with gr.Row():\n",
    "        audio_input = gr.Audio(label=\"Yi Rikodin Magana\")\n",
    "        transcription_output = gr.Textbox(label=\"Rubutaccen Magana\")\n",
    "        \n",
    "    #tts_text = gr.Textbox(label=\"Enter Text for TTS\")\n",
    "    tts_audio = gr.Audio(label=\"Maganar da aka Haifa daga TTS\")\n",
    "    \n",
    "    #buttons\n",
    "    transcribe_button = gr.Button(\"Fassara Sauti\")\n",
    "    response_button = gr.Button(\"Samu Amsa daga Chatbot\")\n",
    "    tts_button = gr.Button(\"Haifar da Magana\")\n",
    "    \n",
    "    # Actions for Buttons\n",
    "    transcribe_button.click(fn=transcribe_audio, inputs=audio_input, outputs=transcription_output)\n",
    "    response_button.click(generate_response, [transcription_output, chatbot], [transcription_output, chatbot], queue=False).then(\n",
    "        bot, chatbot, chatbot\n",
    "    )\n",
    "    tts_button.click(fn=synthesize_speech, inputs=chatbot, outputs=tts_audio)\n",
    "\n",
    "# Launch interface\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc0f2e0a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
